{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation des taux de conversion des versions A et B en tant que séries temporelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Importer les fonctions de visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from part1 import *\n",
    "from part2 import *\n",
    "from part3 import *"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Importer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'C:/Users/Admin/Documents/Centrale Paris/3A/OMA/Projet/Donnees/'\n",
    "annonceur = 'annonceur1/annonceur1'\n",
    "campagne = 'annonceur1_campaign1_visite_engagee'\n",
    "data = pd.read_hdf(folder + annonceur + '.hdf', key=campagne)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On explore les données (répartition des groupes A et B, structure de la table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explorer(data):\n",
    "    print('Début')\n",
    "    print(data.head()) \n",
    "    print('Taille')\n",
    "    print(data.shape)\n",
    "    print('Colonnes')\n",
    "    print(data.columns)\n",
    "    print('Types')\n",
    "    print(data.dtypes)\n",
    "    print('Infos')\n",
    "    print(data.info())\n",
    "    print('Description')\n",
    "    print(data.describe())\n",
    "    \n",
    "    print('Histogramme par groupe') \n",
    "    data.hist(column='is_conv',by='group')\n",
    "    \n",
    "    print('Boxplot par groupe')\n",
    "    data.boxplot(column='is_conv',by='group')\n",
    "    \n",
    "    print('Répartition des groupes')\n",
    "    data['group'].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On prépare la donnée pour l'analyse des taux de conversion: On considère tout d'abord la moyenne des taux de conversion par jour. Pour comparer les deux versions de la bannière publicitaire, on sépare la table initiale en deux sous-tables, l'une pour la version A et l'autre pour la version B. On considère alors la colonne des taux de conversion journaliers comme une série temporelle que nous analysons et comparons entre les versions A et B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparer(data):\n",
    "    print('Conversion des index en dates')\n",
    "    data['impression_date'] = pd.to_datetime(data['impression_date'])\n",
    "    \n",
    "    print('Moyennes des taux par jour et séparation en deux groupes A et B')\n",
    "    dataA = data.loc[data['group']==\"A\",:]\n",
    "    dataA = dataA.groupby(by = dataA['impression_date'].dt.date)[['view','is_conv']].mean()\n",
    "\n",
    "    dataB = data.loc[data['group']==\"B\",:]\n",
    "    dataB = dataB.groupby(by = dataB['impression_date'].dt.date)[['view','is_conv']].mean()\n",
    "    \n",
    "    return dataA, dataB"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Le code suivant trace les fonctions de corrélation caractéristiques de la série des taux de conversion (PACF, ACF), le QQ plot, l'histogramme. Nous regardons également les moyennes flottantes et effets journaliers. \n",
    "\n",
    "Nous affichons également la décomposition de la série temporelle suivant les modèles multiplicatifs et additifs.\n",
    "\n",
    "Nous testons la stationnarité de la série grâce au test de Dickey-Fuller puis appliquons des transformations à la série pour la stationnariser si besoin. Ces transformations combinent la différenciation de la série et le passage au logarithme. Nous réalisons le test de Dickey-Fuller après chacune d'elle afin de déterminer si la stationnarité est atteinte ou non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyser(data):\n",
    "    print('Histogramme')\n",
    "    data.hist(column='is_conv')\n",
    "    \n",
    "    print('Scatter plot')\n",
    "    data.plot.scatter(x='is_conv',y='view')\n",
    "    \n",
    "    print('Densité du taux de conversion')\n",
    "    data['is_conv'].plot.kde()\n",
    "#part 1 du blog\n",
    "    print('Corrélations et covariances')\n",
    "    y = data['is_conv']\n",
    "    y.index = pd.to_datetime(y.index)\n",
    "    corr(y) ## scatter plots pour la corrélation\n",
    "    ts_plot(y) ##analyse classique d'une ST (ACF, PACF, QQ et histo)\n",
    "\n",
    "#part 2 blog\n",
    "    print('Moyennes flottantes')\n",
    "    rolling_mean(y) #regarder la moyenne flottante et l'écart type\n",
    "    plot_rolling_average(y)\n",
    "    \n",
    "    print('Effet journalier')\n",
    "    y2 = pd.Series.to_frame(y)\n",
    "    effet_journalier(y2) #regarder par jour\n",
    "\n",
    "\n",
    "# multiplicative and additive seasonal decomposition\n",
    "\n",
    "##problème de fréquence !!\n",
    "    print('Décomposition de la série de temps')\n",
    "    decomp = seasonal_decompose(y, model='multiplicative',freq=1)\n",
    "    decomp.plot();\n",
    "    plt.show()\n",
    "\n",
    "    decomp = seasonal_decompose(y, model='additive',freq = 1)\n",
    "    decomp.plot();\n",
    "    plt.show()\n",
    "\n",
    "### Part 3: test de Dickey-Fuller\n",
    "    print('Test de Dickey-Fuller')\n",
    "    adf_test(y)\n",
    "    ts_diagnostics(y)\n",
    "\n",
    "# difference time series\n",
    "    print('Stationnariser la série')\n",
    "    print('Différencier')\n",
    "    y_diff = np.diff(y)\n",
    "    ts_diagnostics(y_diff, lags=30)\n",
    "\n",
    "# log transform time series\n",
    "    print('Passer au logarithme')\n",
    "    y_log = np.log(y)\n",
    "    ts_diagnostics(y_log, lags=30)\n",
    "\n",
    " #log difference time series\n",
    "    print('Différencier le logarithme')\n",
    "    y_log_diff = np.log(y).diff().dropna()\n",
    "    ts_diagnostics(y_log_diff, lags=30)\n",
    "\n",
    "# log difference time series *2\n",
    "    print('Différencier le logarithme deux fois')\n",
    "    y_log_diff2 = np.log(y).diff().diff(12).dropna()\n",
    "    ts_diagnostics(y_log_diff2, lags=30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Exemple de lancement du programme avec les données chargées plus haut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA, dataB = preparer(data) \n",
    "explorer(data)  \n",
    "analyser(dataA)\n",
    "analyser(dataB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
